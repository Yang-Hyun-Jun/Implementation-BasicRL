{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4831,"status":"ok","timestamp":1645063281017,"user":{"displayName":"양현준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCzvni_KcFKU5U-vmQ2H1e1aU5225oHgsDxya=s64","userId":"03791106996878442638"},"user_tz":-540},"id":"Gxw684MPFCnD","outputId":"8143804c-8403-4c65-9ba7-4f09805df839"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n","Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym) (1.21.5)\n","Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n","Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.4.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n"]}],"source":["! pip install gym"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":5511,"status":"ok","timestamp":1645063286526,"user":{"displayName":"양현준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCzvni_KcFKU5U-vmQ2H1e1aU5225oHgsDxya=s64","userId":"03791106996878442638"},"user_tz":-540},"id":"JSStPF9dDWxr"},"outputs":[],"source":["import numpy as np\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch\n","import random\n","import gym\n","import threading"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1645063287883,"user":{"displayName":"양현준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCzvni_KcFKU5U-vmQ2H1e1aU5225oHgsDxya=s64","userId":"03791106996878442638"},"user_tz":-540},"id":"Mk9_GaWOE_ah","outputId":"eb6dd761-52b6-4ca8-b149-b523aa1bad42"},"outputs":[{"data":{"text/plain":["<TimeLimit<CartPoleEnv<CartPole-v1>>>"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["Env = gym.make(\"CartPole-v1\")\n","Env"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1645063287884,"user":{"displayName":"양현준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCzvni_KcFKU5U-vmQ2H1e1aU5225oHgsDxya=s64","userId":"03791106996878442638"},"user_tz":-540},"id":"Qv8M1LlVcagm","outputId":"a0d05ba0-468f-4b04-cfd6-2edc06701bac"},"outputs":[{"name":"stdout","output_type":"stream","text":["(4,) Discrete(2)\n"]}],"source":["input_dim = Env.observation_space.shape\n","output_dim = Env.action_space\n","print(input_dim, output_dim)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1645063287884,"user":{"displayName":"양현준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCzvni_KcFKU5U-vmQ2H1e1aU5225oHgsDxya=s64","userId":"03791106996878442638"},"user_tz":-540},"id":"wNlJwxi2EaX9","outputId":"2472e009-e6d6-46dd-f985-1320f21e8a99"},"outputs":[{"data":{"text/plain":["array([-0.04129239, -0.03440432,  0.01166018,  0.04215938])"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["Env.reset()"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1645063287885,"user":{"displayName":"양현준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCzvni_KcFKU5U-vmQ2H1e1aU5225oHgsDxya=s64","userId":"03791106996878442638"},"user_tz":-540},"id":"KZ7xYLIbGbdd"},"outputs":[],"source":["#Soft target update\n","def soft_update(net, net_target, tau):\n","  for param_target, param in zip(net_target.parameters(), net.parameters()):\n","    param_target.data.copy_(param_target.data*(1.0-tau) + param.data*tau)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":325,"status":"ok","timestamp":1645063420766,"user":{"displayName":"양현준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCzvni_KcFKU5U-vmQ2H1e1aU5225oHgsDxya=s64","userId":"03791106996878442638"},"user_tz":-540},"id":"WSbQ2jD-Hglm"},"outputs":[],"source":["class DNN(nn.Module):\n","  def __init__(self, \n","               input_dim: int, output_dim: int,\n","               hidden_act: str, out_act: str):\n","    super().__init__()\n","\n","    self.hidden_act = getattr(nn, hidden_act)()\n","    self.out_act = getattr(nn, out_act)()\n","\n","    self.layers = nn.ModuleList()\n","    self.layers.append(nn.Linear(input_dim, 16))\n","    self.layers.append(self.hidden_act)\n","    self.layers.append(nn.Linear(16, 32))\n","    self.layers.append(self.hidden_act)\n","    self.layers.append(nn.Linear(32, 64))\n","    self.layers.append(self.hidden_act)\n","    self.layers.append(nn.Linear(64, output_dim))\n","    self.layers.append(self.out_act)\n","\n","  def forward(self, x):\n","    for layer in self.layers:\n","      x = layer(x)\n","    return x"]},{"cell_type":"code","execution_count":94,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1645066509540,"user":{"displayName":"양현준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCzvni_KcFKU5U-vmQ2H1e1aU5225oHgsDxya=s64","userId":"03791106996878442638"},"user_tz":-540},"id":"3JAkt6g-HtwI"},"outputs":[],"source":["class DQNrunner(nn.Module, threading.Thread):\n","  def __init__(self, ADQNagent, env,\n","               qnet:nn.Module, qnet_target:nn.Module, \n","               lr:float, discount_factor:float, epsilon:float,\n","               target_update_interval:float,\n","               async_update_interval:float, \n","               num_epi:float, tau:float):\n","    \n","    nn.Module.__init__(self)\n","    threading.Thread.__init__(self)\n","\n","    self.Lock = threading.Lock()\n","    self.env = env\n","    self.ADQNagent = ADQNagent\n","    self.qnet = qnet\n","    self.qnet_target = qnet_target\n","\n","    self.lr = lr\n","    self.tau = tau\n","    self.discount_factor = discount_factor\n","    self.epsilon = epsilon\n","    self.num_epi = num_epi\n","    self.target_update_interval = target_update_interval\n","    self.async_update_interval = async_update_interval\n","\n","    self.criteria = nn.MSELoss()\n","    self.optimizer = torch.optim.Adam(params=qnet.parameters(), lr=lr)\n","    \n","  def get_action(self, state):\n","    if np.random.uniform(0, 1, size=1) <= self.epsilon:\n","      action = np.random.choice([0, 1], size=1, p=[1/2, 1/2])\n","      return torch.tensor(action).numpy()[0]\n","    else:\n","      state = torch.tensor(state).float().view(1,-1)\n","      q = self.qnet(state).detach()\n","      actions = torch.argmax(q).numpy()\n","      action = np.max(actions)\n","      return action\n","\n","  def cum_gradient(self, state, action, next_state, reward, done):\n","    s, a, r, ns = state, action, reward, next_state\n","\n","    with torch.no_grad():\n","      q = self.qnet_target(ns)\n","      q_max = torch.max(q)\n","      target = r + self.discount_factor*q_max*(1-done).clone()\n","    \n","    infer = self.qnet(s).clone()\n","    loss = self.criteria(infer[0][a], target)\n","    loss.backward()\n","\n","  def main_update(self):\n","    for paramA, paramB in zip(self.ADQNagent.global_qnet.parameters(), self.qnet.parameters()):\n","      paramA.grad = paramB.grad\n","    self.ADQNagent.optimizer.step()\n","    self.ADQNagent.optimizer.zero_grad()\n","    self.qnet.load_state_dict(self.ADQNagent.global_qnet.state_dict())\n","\n","  def run(self):\n","    self.qnet_target.load_state_dict(self.qnet.state_dict())\n","    \n","    for epi in range(self.num_epi):\n","      cum_r = 0\n","      state = self.env.reset()\n","      while True:\n","        action = self.get_action(state)\n","        next_state, reward, done, info = self.env.step(action)\n","\n","        if done: \n","          done = 1\n","        else: \n","          done = 0\n","\n","        state = torch.tensor(state).float().view(1, -1)\n","        action = torch.tensor(action)\n","        next_state = torch.tensor(next_state).float().view(1, -1)\n","        reward = torch.tensor(reward)\n","        done = torch.tensor(done)\n","\n","        self.cum_gradient(state, action, next_state, reward, done)\n","        cum_r += reward\n","        if done:\n","          self.main_update()\n","          break\n","      \n","      if epi % self.target_update_interval == 0:\n","        soft_update(self.qnet, self.qnet_target, self.tau)\n","      \n","      if epi & self.async_update_interval == 0:\n","        self.main_update()\n","        print(\"Episode: {} | cum_r: {} | main_update complete\".format(epi, cum_r))"]},{"cell_type":"code","execution_count":96,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1645066509541,"user":{"displayName":"양현준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCzvni_KcFKU5U-vmQ2H1e1aU5225oHgsDxya=s64","userId":"03791106996878442638"},"user_tz":-540},"id":"FtUNUoYlT4mV"},"outputs":[],"source":["class ADQN(nn.Module):\n","  def __init__(self, \n","               local_qnet:nn.Module,\n","               global_qnet:nn.Module, global_lr:float, thread_num:int):\n","    super().__init__()\n","    self.global_qnet = global_qnet\n","    self.local_qnet = local_qnet\n","    self.global_lr = global_lr\n","    self.thread_num = thread_num\n","    self.optimizer = torch.optim.Adam(params=self.global_qnet.parameters(), lr=self.global_lr)\n","\n","  def get_action(self, state):\n","    state = torch.tensor(state).float().view(1,-1)\n","    q = self.global_qnet(state).detach()\n","    action = torch.argmax(q)\n","    return action\n","\n","  def train(self):\n","    runners = [DQNrunner(env=Env,qnet=self.local_qnet, qnet_target=self.local_qnet, ADQNagent=self,\n","                         lr=0.001, discount_factor=0.99, epsilon=1.0,\n","                         target_update_interval=20,\n","                         async_update_interval=50,\n","                         num_epi=200, tau=0.002) for _ in range(self.thread_num)]    \n","\n","    for i, runner in enumerate(runners):\n","      print(\"Start runner #{}\".format(i))\n","      runner.start()"]}],"metadata":{"colab":{"name":"Asynchronous Q-Learning.ipynb","provenance":[{"file_id":"13vPUjpKIZ4e6lOR_5O0EUQL_WrCcu0Sz","timestamp":1644925558005},{"file_id":"1lGxeZwcpIZSAGL6kUoNlAZMXVRs1kvv7","timestamp":1644893280323}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
