{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Naive Deep Q-Learning.ipynb","provenance":[],"authorship_tag":"ABX9TyO0byiwh18hfzlb52IeNrK7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Sj-4zE2RCZI","executionInfo":{"status":"ok","timestamp":1644423919445,"user_tz":-540,"elapsed":4157,"user":{"displayName":"양현준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCzvni_KcFKU5U-vmQ2H1e1aU5225oHgsDxya=s64","userId":"03791106996878442638"}},"outputId":"88fb2a1c-00bc-469e-9d0a-e01d81cd72e2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n","Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n","Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.4.1)\n","Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym) (1.19.5)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n"]}],"source":["! pip install gym"]},{"cell_type":"code","source":["import gym\n","import numpy as np\n","import torch\n","import torch.nn as nn"],"metadata":{"id":"jyPpjavGRb5x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#CartPole 환경 생성\n","#(위치, 각도, 속도, 각속도)\n","env = gym.make(\"CartPole-v1\")\n","env.reset()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GZFZE0jKRimP","executionInfo":{"status":"ok","timestamp":1644423926210,"user_tz":-540,"elapsed":14,"user":{"displayName":"양현준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCzvni_KcFKU5U-vmQ2H1e1aU5225oHgsDxya=s64","userId":"03791106996878442638"}},"outputId":"0f8719f2-2641-4ad6-9313-338ea4fea411"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 0.01320257, -0.01019533,  0.03457361, -0.01318813])"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["#임의의 행동으로 한 스텝 진행\n","print(env.action_space.sample())\n","print(env.step(env.action_space.sample())) #(ns, r, done, info) 리턴"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0mwM-CaAR-Eu","executionInfo":{"status":"ok","timestamp":1644423926211,"user_tz":-540,"elapsed":11,"user":{"displayName":"양현준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCzvni_KcFKU5U-vmQ2H1e1aU5225oHgsDxya=s64","userId":"03791106996878442638"}},"outputId":"0728fa0e-e022-4c8c-9413-990b5befd370"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1\n","(array([ 0.01299866, -0.20579561,  0.03430985,  0.29019958]), 1.0, False, {})\n"]}]},{"cell_type":"code","source":["#상태공간 및 행동공간 확인하기\n","s_dim = env.observation_space.shape[0]\n","a_dim = env.action_space.n\n","\n","print(\"state space dimension: {}\".format(s_dim))\n","print(\"action space dimension: {}\".format(a_dim))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r52C2WCrTS9t","executionInfo":{"status":"ok","timestamp":1644423926211,"user_tz":-540,"elapsed":9,"user":{"displayName":"양현준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCzvni_KcFKU5U-vmQ2H1e1aU5225oHgsDxya=s64","userId":"03791106996878442638"}},"outputId":"2a3b574d-00ca-43d0-b63b-ff0176decbd7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["state space dimension: 4\n","action space dimension: 2\n"]}]},{"cell_type":"code","source":["#현재 상태 받아오기\n","env.state"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WftwPseZT42t","executionInfo":{"status":"ok","timestamp":1644423926211,"user_tz":-540,"elapsed":8,"user":{"displayName":"양현준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCzvni_KcFKU5U-vmQ2H1e1aU5225oHgsDxya=s64","userId":"03791106996878442638"}},"outputId":"dfdbcd80-21d4-4fbb-eedb-281132e2f71e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0.012998663920133236,\n"," -0.20579561393908874,\n"," 0.03430985168543008,\n"," 0.2901995807180004)"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["#MLP 구현\n","class MultiLayerPerceptron(nn.Module):\n","  def __init__(self, \n","               input_dim:int, output_dim:int,\n","               num_neurons:list, hidden_act:str, out_act: str):\n","\n","    super().__init__()\n","    self.input_dim = input_dim\n","    self.output_dim = output_dim\n","    self.num_neurons = num_neurons\n","    self.hidden_act = getattr(nn, hidden_act)()\n","    self.out_act = getattr(nn, out_act)()\n","\n","    input_dims = [input_dim] + num_neurons\n","    output_dims = num_neurons + [output_dim]\n","    \n","    self.layers = nn.ModuleList()\n","    for i, (in_dim, out_dim) in enumerate(zip(input_dims, output_dims)):\n","      is_last = True if i == len(input_dims) else False\n","      self.layers.append(nn.Linear(in_dim, out_dim))\n","      if is_last:\n","        self.layers.append(self.out_act)\n","      else:\n","        self.layers.append(self.hidden_act)\n","\n","    # self.layers = nn.ModuleList()\n","    # self.layers.append(nn.Linear(1, 16))\n","    # self.layers.append(nn.ReLU())\n","    # self.layers.append(nn.Linear(16, 32))\n","    # self.layers.append(nn.ReLU())\n","    # self.layers.append(nn.Linear(32, 64))\n","\n","  def forward(self, xs):\n","    for layer in self.layers:\n","      xs = layer(xs)\n","    return xs"],"metadata":{"id":"t-vtCS7lZnMO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Navie DQN 구현\n","class NaiveDQN(nn.Module):\n","  def __init__(self, \n","               state_dim:int, action_dim:int,\n","               qnet:nn.Module, lr:float, gamma:float, epsilon:float):\n","    \n","    super(NaiveDQN, self).__init__()\n","    self.state_dim = state_dim\n","    self.action_dim = action_dim\n","    self.qnet = qnet\n","    self.lr = lr\n","    self.gamma = gamma\n","    self.epsilon = epsilon\n","\n","    self.opt = torch.optim.Adam(params=self.qnet.parameters(), lr=lr)\n","    self.register_buffer(\"epsilons\", torch.ones(1)*epsilon)\n","    self.criteria = nn.MSELoss()\n","\n","  def get_action(self, state):\n","    qs = self.qnet(state) #qs는 batch x action\n","\n","    #epislon-greedy\n","    if self.train:\n","      prop = np.random.uniform(0.0, 1.0, 1)\n","      if torch.from_numpy(prop).float() <= self.epsilon: \n","        action = np.random.choice(range(self.action_dim))\n","      else: \n","        action = qs.argmax(dim=-1)\n","      return int(action)\n","  \n","  def update_sample(self, state, action, reward, next_state, done):\n","    s, a, r, ns = state, action, reward, next_state\n","    #Q-Learning target\n","    q_max, _ = self.qnet(next_state).max(dim=-1)\n","    q_target = r + self.gamma * q_max * (1-done)\n","    q_target = q_target.detach()\n","\n","    \"\"\"\n","    with torch.no_grad():\n","      q_max, _ = self.qnet(next_state).max(dim=-1)\n","      q_target = r + self.gamma * q_max * (1-done)\n","\n","    \"\"\"\n","\n","    loss = self.criteria(self.qnet(s)[0, action], q_target)\n","    self.opt.zero_grad()\n","    loss.backward()\n","    self.opt.step()"],"metadata":{"id":"W-pINv-HwUd6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["qnet = MultiLayerPerceptron(input_dim=s_dim,\n","                            output_dim=a_dim,\n","                            num_neurons=[128],\n","                            hidden_act=\"ReLU\",\n","                            out_act=\"Identity\")\n","\n","agent = NaiveDQN(state_dim=s_dim, \n","                 action_dim=a_dim,\n","                 qnet=qnet,\n","                 lr=1e-4,\n","                 gamma=1.0,\n","                 epsilon=1.0)"],"metadata":{"id":"K_VoWnshuXjD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#에이전트의 성능 평가를 위한 이동평균 계산기\n","class EMA:\n","  def __init__(self, alpha:float = 0.5):\n","    self.s = None\n","    self.alpha = alpha\n","\n","  def update(self, y):\n","    if self.s is None:\n","      self.s = y\n","    else:\n","      self.s = self.alpha*y + (1-self.alpha)*self.s"],"metadata":{"id":"jt-D_JcrxbXc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#리워드 합으로 평가\n","n_eps = 10000\n","print_every = 500\n","ema_factor = 0.5\n","ema = EMA(ema_factor)\n","\n","for ep in range(n_eps):\n","  env.reset()\n","  cum_r = 0 #누적 보상\n","  while True:\n","    s = env.state\n","    s = torch.tensor(s).float().view(1, 4) #float32 아니면 error\n","    a = agent.get_action(s)\n","    ns, r, done, info = env.step(a)\n","\n","    ns = torch.tensor(ns).float()\n","    agent.update_sample(s, a, r, ns, done)\n","    cum_r += r\n","    if done:\n","      ema.update(cum_r)\n","\n","      if ep % print_every == 0:\n","        print(\"Episode {} || EMA: {} || eps: {}\".format(ep, ema.s, agent.epsilon))\n","    \n","      if ep>= 150:\n","        agent.epsilon *= 0.999\n","      break\n","env.close()"],"metadata":{"id":"DMZG2ch81hWa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####.detach()에 관하여"],"metadata":{"id":"dUAdBfP69AKE"}},{"cell_type":"code","source":["mlp = MultiLayerPerceptron(input_dim=4,\n","                           output_dim=2,\n","                           num_neurons=[64, 32],\n","                           hidden_act=\"ReLU\",\n","                           out_act=\"Identity\")"],"metadata":{"id":"5_DsyaWFftT8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["xs = np.random.uniform(1.0, 10.0, size=(10, 4))\n","xs = torch.from_numpy( xs ).view(10, 4).float()\n","xs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-1iz2ImWo7N4","executionInfo":{"status":"ok","timestamp":1642605787069,"user_tz":-540,"elapsed":517,"user":{"displayName":"양현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03791106996878442638"}},"outputId":"02a95f3d-eb03-4e21-f374-ca8ce84a0129"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[6.3921, 2.6298, 7.4136, 4.7489],\n","        [4.9340, 1.1022, 3.0610, 2.5916],\n","        [6.7262, 3.9927, 8.0141, 7.0119],\n","        [3.1749, 8.2022, 4.3721, 8.5152],\n","        [3.1802, 8.9127, 5.8001, 3.8845],\n","        [7.1603, 6.5441, 1.0765, 3.9276],\n","        [8.5353, 1.3522, 9.2767, 8.5346],\n","        [4.3007, 9.4684, 2.3827, 1.2168],\n","        [8.0778, 4.3005, 6.8617, 9.1942],\n","        [2.3993, 6.6922, 5.8740, 2.0673]])"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["#.detach()로 그라디언트 트래킹 끄기\n","print(mlp(xs).requires_grad)\n","print(mlp(xs).detach().requires_grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9oUTjHY1sup7","executionInfo":{"status":"ok","timestamp":1642602002421,"user_tz":-540,"elapsed":336,"user":{"displayName":"양현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03791106996878442638"}},"outputId":"3bb1a5ca-83da-454c-b2a2-ea7d2163900f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","False\n"]}]},{"cell_type":"code","source":["#with문으로 끄기 \n","with torch.no_grad():\n","  print(mlp(xs).requires_grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8UR15p8es7xl","executionInfo":{"status":"ok","timestamp":1642601917326,"user_tz":-540,"elapsed":285,"user":{"displayName":"양현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03791106996878442638"}},"outputId":"1a733079-2f39-4cfd-d889-3fd8ec1714b9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["False\n"]}]},{"cell_type":"code","source":["#모델 파라미터 출력\n","mlp.state_dict()"],"metadata":{"id":"chwHo5LEshXy"},"execution_count":null,"outputs":[]}]}