{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DQN.ipynb","provenance":[],"authorship_tag":"ABX9TyNdPb7ZDhvwULDDGU49i4F6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["! pip install gym"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nOIZpuXeJCdI","executionInfo":{"status":"ok","timestamp":1643028695984,"user_tz":-540,"elapsed":4200,"user":{"displayName":"양현준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCzvni_KcFKU5U-vmQ2H1e1aU5225oHgsDxya=s64","userId":"03791106996878442638"}},"outputId":"e221b6d1-059d-465f-94d0-3363edd6a545"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n","Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym) (1.19.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.4.1)\n","Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n","Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X25VIKeHXtiA"},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import gym\n","import random\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","source":["env = gym.make(\"CartPole-v1\")\n","env"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nKmi_BxNJB_t","executionInfo":{"status":"ok","timestamp":1643028719839,"user_tz":-540,"elapsed":387,"user":{"displayName":"양현준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCzvni_KcFKU5U-vmQ2H1e1aU5225oHgsDxya=s64","userId":"03791106996878442638"}},"outputId":"dbdd6bc0-4906-450b-b52e-12691763aa01"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<TimeLimit<CartPoleEnv<CartPole-v1>>>"]},"metadata":{},"execution_count":122}]},{"cell_type":"code","source":["s_dim = env.observation_space.shape[0]\n","a_dim = env.action_space.n\n","\n","print(f\"상태 공간 크기: {s_dim}\")\n","print(f\"행동 공간 크기: {a_dim}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CZC8tSl6JMlz","executionInfo":{"status":"ok","timestamp":1643028854964,"user_tz":-540,"elapsed":448,"user":{"displayName":"양현준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCzvni_KcFKU5U-vmQ2H1e1aU5225oHgsDxya=s64","userId":"03791106996878442638"}},"outputId":"c88807bd-806e-46e8-a9a4-a3c129721ac3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["상태 공간 크기: 4\n","행동 공간 크기: 2\n"]}]},{"cell_type":"code","source":["#Experience Replay (deque 대신)\n","class ReplayMemory:\n","  def __init__(self, max_size):\n","    self.buffer = [None]*max_size\n","    self.max_size = max_size\n","    self.index = 0\n","    self.size = 0\n","\n","  def push(self, obj):\n","    self.buffer[self.index] = obj\n","    self.size = min(self.size+1, self.max_size)\n","    #max_size 넘어가면 다시 인덱스 = 0 \n","    self.index = (self.index+1) % self.max_size \n","  \n","  def sample(self, batch_size):\n","    #배치 사이즈만큼 랜덤하게 인덱스 추출\n","    indices = random.sample(range(self.size), batch_size) \n","    return [self.buffer[index] for index in indices]\n","\n","  def __len__(self):\n","    return self.size"],"metadata":{"id":"QrBrM9DSe4EB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#MLP\n","class MultiLayerPerceptron(nn.Module):\n","  def __init__(self, \n","               input_dim:int, output_dim:int,\n","               hidden_act:str, out_act: str):\n","\n","    super().__init__()\n","    self.input_dim = input_dim\n","    self.output_dim = output_dim\n","    self.hidden_act = getattr(nn, hidden_act)()\n","    self.out_act = getattr(nn, out_act)()\n","\n","    self.layers = nn.ModuleList()\n","    self.layers.append(nn.Linear(self.input_dim, 16))\n","    self.layers.append(self.hidden_act)\n","    self.layers.append(nn.Linear(16, 32))\n","    self.layers.append(self.hidden_act)\n","    self.layers.append(nn.Linear(32, 64))\n","    self.layers.append(self.hidden_act)\n","    self.layers.append(nn.Linear(64, self.output_dim))\n","    self.layers.append(self.out_act)\n","\n","  def forward(self, xs):\n","    for layer in self.layers:\n","      xs = layer(xs)\n","    return xs"],"metadata":{"id":"83vwgHXCkKzC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#DQN\n","class DQN(nn.Module):\n","  def __init__(self, \n","               state_dim:int,\n","               action_dim:int,\n","               qnet:nn.Module,\n","               qnet_target:nn.Module,\n","               lr:float,\n","               gamma:float,\n","               epsilon:float):\n","    super(DQN, self).__init__()\n","    self.state_dim = state_dim\n","    self.action_dim = action_dim\n","    self.qnet = qnet\n","    self.qnet_target = qnet_target\n","    self.lr = lr\n","    self.gamma = gamma\n","    \n","    self.opt = torch.optim.Adam(params=self.qnet.parameters(), lr=lr)\n","    self.register_buffer(\"epsilon\", torch.ones(1)*epsilon)\n","    self.criteria = nn.SmoothL1Loss()\n","\n","  def get_action(self, state):\n","    q_value = self.qnet(state)\n","    prob = np.random.uniform(low=0.0, high=1.0, size=1)\n","    prob = torch.tensor(prob).float()\n","    if prob <= self.epsilon:\n","      action = np.random.choice(range(self.action_dim))\n","    else:\n","      action = q_value.argmax(dim=-1)\n","    return int(action)\n","\n","  def update(self, state, action, reward, next_state, done):\n","    s, a, r, ns = state, action, reward, next_state\n","\n","    with torch.no_grad():\n","      q_max, _ = self.qnet_target(ns).max(dim=-1, keepdims=True)\n","      target = r + self.gamma*q_max*(1-done)\n","    \n","    q = self.qnet(s).gather(1, a)\n","    loss = self.criteria(q, target)\n","\n","    self.opt.zero_grad()\n","    loss.backward()\n","    self.opt.step()"],"metadata":{"id":"0jlUUiBDkWWY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def prepare_training_inputs(sampled_exps, device=\"cpu\"):\n","  states = []\n","  actions = []\n","  rewards = []\n","  next_states = []\n","  dones = []\n","\n","  for sampled_exp in sampled_exps:\n","    states.append(sampled_exp[0])\n","    actions.append(sampled_exp[1])\n","    rewards.append(sampled_exp[2])\n","    next_states.append(sampled_exp[3])\n","    dones.append(sampled_exp[4])\n","  \n","  states = torch.cat(states, dim=0).float().to(device)\n","  actions = torch.cat(actions, dim=0).to(device)\n","  rewards = torch.cat(rewards, dim=0).float().to(device)\n","  next_states = torch.cat(next_states, dim=0).float().to(device)\n","  dones = torch.cat(dones, dim=0).float().to(device)\n","  return states, actions, rewards, next_states, dones"],"metadata":{"id":"WrYS-KlgcLs1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#텐서 변환\n","def to_tensor(data, size):\n","  return torch.tensor(data).float().view(size)"],"metadata":{"id":"N4nSO9SUVTaz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lr = 1e-4 * 5\n","batch_size = 256\n","gamma = 1.0\n","memory_size = 50000\n","total_eps = 3000\n","eps_max = 0.08\n","eps_min = 0.01\n","sampling_only_until = 2000\n","target_update_interval = 10"],"metadata":{"id":"RKLE-mX_KgE_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["qnet = MultiLayerPerceptron(input_dim=s_dim,\n","                            output_dim=a_dim,\n","                            hidden_act=\"ReLU\",\n","                            out_act=\"Identity\")\n","\n","qnet_target = MultiLayerPerceptron(input_dim=s_dim,\n","                            output_dim=a_dim,\n","                            hidden_act=\"ReLU\",\n","                            out_act=\"Identity\")\n","\n","agent = DQN(state_dim=s_dim, \n","            action_dim=a_dim,\n","            qnet=qnet,  \n","            qnet_target=qnet_target,\n","            lr=lr, gamma=gamma, epsilon=1.0)\n","\n","memory = ReplayMemory(memory_size)"],"metadata":{"id":"KQmhCInUI-Ij"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print_every = 100\n","qnet_target.load_state_dict(qnet.state_dict())\n"," \n","for n_epi in range(total_eps):\n","  #epsilon scheduling\n","  #slowly decaying_epsilon\n","  epsilon = max( eps_min, eps_max-eps_min*(n_epi/200) )\n","  agent.epsilon = torch.tensor(epsilon)\n","  s = env.reset()\n","  cum_r = 0\n","  while True: \n","    s = torch.tensor(s).float().view(1, 4)\n","    a = agent.get_action(s)\n","    ns, r, done, info = env.step(a)\n","    \n","    #batch shape 변환 후 sample 생성\n","    experience = (s, \n","                  torch.tensor(a).view(1, 1) ,\n","                  torch.tensor(r/100).view(1, 1), #1/100 scaling\n","                  torch.tensor(ns).float().view(1, 4), \n","                  torch.tensor(done).view(1, 1)) \n","    #샘플 저장\n","    memory.push(experience)\n","\n","    s = ns\n","    cum_r += r\n","    if done:\n","      break\n","  \n","  if len(memory) >= sampling_only_until:\n","    #train agent\n","    sampled_exps = memory.sample(batch_size)\n","    sampled_exps = prepare_training_inputs(sampled_exps)\n","    agent.update(*sampled_exps)\n","\n","  if n_epi % target_update_interval == 0:\n","    qnet_target.load_state_dict(qnet.state_dict())\n","  \n","  if n_epi % print_every == 0:\n","    msg = (n_epi, cum_r, epsilon)\n","    print(\"Episode: {:4.0f} | Cum R: {:4.0f} | Epsilon: {:.3f}\".format(*msg))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1YKVBHz9CvbG","executionInfo":{"status":"ok","timestamp":1643039398677,"user_tz":-540,"elapsed":250145,"user":{"displayName":"양현준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCzvni_KcFKU5U-vmQ2H1e1aU5225oHgsDxya=s64","userId":"03791106996878442638"}},"outputId":"09232a4d-ceef-44c1-eaf0-6571b0e3582c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Episode:    0 | Cum R:   10 | Epsilon: 0.080\n","Episode:  100 | Cum R:    9 | Epsilon: 0.075\n","Episode:  200 | Cum R:   10 | Epsilon: 0.070\n","Episode:  300 | Cum R:   22 | Epsilon: 0.065\n","Episode:  400 | Cum R:  108 | Epsilon: 0.060\n","Episode:  500 | Cum R:   75 | Epsilon: 0.055\n","Episode:  600 | Cum R:  119 | Epsilon: 0.050\n","Episode:  700 | Cum R:  122 | Epsilon: 0.045\n","Episode:  800 | Cum R:  175 | Epsilon: 0.040\n","Episode:  900 | Cum R:  237 | Epsilon: 0.035\n","Episode: 1000 | Cum R:  159 | Epsilon: 0.030\n","Episode: 1100 | Cum R:  383 | Epsilon: 0.025\n","Episode: 1200 | Cum R:  500 | Epsilon: 0.020\n","Episode: 1300 | Cum R:  476 | Epsilon: 0.015\n","Episode: 1400 | Cum R:  164 | Epsilon: 0.010\n","Episode: 1500 | Cum R:  106 | Epsilon: 0.010\n","Episode: 1600 | Cum R:  430 | Epsilon: 0.010\n","Episode: 1700 | Cum R:  144 | Epsilon: 0.010\n","Episode: 1800 | Cum R:  479 | Epsilon: 0.010\n","Episode: 1900 | Cum R:  494 | Epsilon: 0.010\n","Episode: 2000 | Cum R:  500 | Epsilon: 0.010\n","Episode: 2100 | Cum R:  351 | Epsilon: 0.010\n","Episode: 2200 | Cum R:  500 | Epsilon: 0.010\n","Episode: 2300 | Cum R:  500 | Epsilon: 0.010\n","Episode: 2400 | Cum R:  500 | Epsilon: 0.010\n","Episode: 2500 | Cum R:  500 | Epsilon: 0.010\n","Episode: 2600 | Cum R:  500 | Epsilon: 0.010\n","Episode: 2700 | Cum R:  500 | Epsilon: 0.010\n","Episode: 2800 | Cum R:  500 | Epsilon: 0.010\n","Episode: 2900 | Cum R:  500 | Epsilon: 0.010\n"]}]}]}