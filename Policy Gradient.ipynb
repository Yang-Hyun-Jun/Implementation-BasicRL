{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Policy Gradient.ipynb","provenance":[],"authorship_tag":"ABX9TyO14pRRSrvt6IejuFE3dGcn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OOcAmQz9ydtJ","executionInfo":{"status":"ok","timestamp":1642775320538,"user_tz":-540,"elapsed":3598,"user":{"displayName":"양현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03791106996878442638"}},"outputId":"5ed42391-bcec-495c-d04a-af688b349cf4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n","Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym) (1.19.5)\n","Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n","Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.4.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n"]}],"source":["! pip install gym"]},{"cell_type":"code","source":["import gym\n","import torch\n","import matplotlib.pyplot as plt\n","import torch.nn as nn \n","\n","from torch.distributions.categorical import Categorical"],"metadata":{"id":"pvhYTOhjyoVm","executionInfo":{"status":"ok","timestamp":1642775320538,"user_tz":-540,"elapsed":25,"user":{"displayName":"양현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03791106996878442638"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["env = gym.make(\"CartPole-v1\")\n","s_dim = env.observation_space.shape[0]\n","a_dim = env.action_space.n"],"metadata":{"id":"MrQRHSaR0Dno","executionInfo":{"status":"ok","timestamp":1642775320539,"user_tz":-540,"elapsed":24,"user":{"displayName":"양현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03791106996878442638"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["#MLP\n","class MultiLayerPerceptron(nn.Module):\n","  def __init__(self, \n","               input_dim:int, output_dim:int,\n","               hidden_act:str, out_act: str):\n","\n","    super().__init__()\n","    self.input_dim = input_dim\n","    self.output_dim = output_dim\n","    self.hidden_act = getattr(nn, hidden_act)()\n","    self.out_act = getattr(nn, out_act)()\n","\n","    self.layers = nn.ModuleList()\n","    self.layers.append(nn.Linear(self.input_dim, 16))\n","    self.layers.append(self.hidden_act)\n","    self.layers.append(nn.Linear(16, 32))\n","    self.layers.append(self.hidden_act)\n","    self.layers.append(nn.Linear(32, 64))\n","    self.layers.append(self.hidden_act)\n","    self.layers.append(nn.Linear(64, self.output_dim))\n","    self.layers.append(self.out_act)\n","\n","  def forward(self, xs):\n","    for layer in self.layers:\n","      xs = layer(xs)\n","    return xs"],"metadata":{"id":"HhqMHzvgBVYh","executionInfo":{"status":"ok","timestamp":1642777051930,"user_tz":-540,"elapsed":475,"user":{"displayName":"양현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03791106996878442638"}}},"execution_count":73,"outputs":[]},{"cell_type":"code","source":["class REINFORCE(nn.Module):\n","  def __init__(self, policy:nn.Module, gamma:float=1.0, lr:float=0.0002):\n","    super(REINFORCE, self).__init__()\n","    self.policy = policy\n","    self.gamma = gamma\n","    self.lr = lr\n","    self.opt = torch.optim.Adam(params=self.policy.parameters(), lr=lr)\n","    self._eps = 1e-25\n","\n","  def get_action(self, state):\n","    with torch.no_grad():\n","      logits = self.policy(state)\n","      dist = Categorical(logits=logits)\n","      a = dist.sample()\n","    return a\n","  \n","  @staticmethod\n","  def _pre_process_inputs(episode:tuple):\n","    states, actions, rewards = episode\n","\n","    states = states.flip(dims=[0])\n","    actions = actions.flip(dims=[0])\n","    rewards = rewards.flip(dims=[0])\n","    return states, actions, rewards\n","  \n","  def update_episode(self, episode):\n","    # sample-by-sample update (inefficient)\n","    states, actions, rewards = self._pre_process_inputs(episode)\n","\n","    g = 0 \n","    for s, a, r in zip(states, actions, rewards):\n","      g = r + self.gamma*g\n","      dist = Categorical(logits=self.policy(s))\n","      prob = dist.probs[a]\n","      pg_loss = -torch.log(prob + self._eps)*g # minus for gradient ascent\n","      \n","      self.opt.zero_grad()\n","      pg_loss.backward()\n","      self.opt.step()"],"metadata":{"id":"PDtiqw7JDXni","executionInfo":{"status":"ok","timestamp":1642776405194,"user_tz":-540,"elapsed":473,"user":{"displayName":"양현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03791106996878442638"}}},"execution_count":70,"outputs":[]},{"cell_type":"code","source":["#에이전트의 성능 평가를 위한 이동평균 계산기\n","class EMA:\n","  def __init__(self, alpha:float = 0.5):\n","    self.s = None\n","    self.alpha = alpha\n","\n","  def update(self, y):\n","    if self.s is None:\n","      self.s = y\n","    else:\n","      self.s = self.alpha*y + (1-self.alpha)*self.s"],"metadata":{"id":"RXIirPUVVK1R","executionInfo":{"status":"ok","timestamp":1642775746808,"user_tz":-540,"elapsed":3,"user":{"displayName":"양현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03791106996878442638"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["#텐서 변환\n","def to_tensor(data, size):\n","  return torch.tensor(data).float().view(size)"],"metadata":{"id":"3t5u0gs4ewJ6","executionInfo":{"status":"ok","timestamp":1642775747458,"user_tz":-540,"elapsed":2,"user":{"displayName":"양현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03791106996878442638"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["net = MultiLayerPerceptron(input_dim=s_dim, \n","                           output_dim=a_dim,\n","                           hidden_act=\"ReLU\",\n","                           out_act=\"Identity\")\n","\n","agent = REINFORCE(net)\n","ema = EMA()"],"metadata":{"id":"MwilPW9-SlpA","executionInfo":{"status":"ok","timestamp":1642777730415,"user_tz":-540,"elapsed":367,"user":{"displayName":"양현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03791106996878442638"}}},"execution_count":93,"outputs":[]},{"cell_type":"code","source":["net.layers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mqLSU05mDOau","executionInfo":{"status":"ok","timestamp":1642777731273,"user_tz":-540,"elapsed":4,"user":{"displayName":"양현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03791106996878442638"}},"outputId":"6ae20007-5834-4896-fc49-15ca9bc1f135"},"execution_count":94,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ModuleList(\n","  (0): Linear(in_features=4, out_features=16, bias=True)\n","  (1): ReLU()\n","  (2): Linear(in_features=16, out_features=32, bias=True)\n","  (3): ReLU()\n","  (4): Linear(in_features=32, out_features=64, bias=True)\n","  (5): ReLU()\n","  (6): Linear(in_features=64, out_features=2, bias=True)\n","  (7): Identity()\n",")"]},"metadata":{},"execution_count":94}]},{"cell_type":"code","source":["n_eps = 2000\n","print_every = 500\n","\n","for ep in range(n_eps):\n","  s = env.reset()\n","  cum_r = 0\n","\n","  states = []\n","  actions = []\n","  rewards = []\n","  \n","  #정책에 따라 trajectory 형성\n","  while True:\n","    s = to_tensor(s, size=(1,4))\n","    a = agent.get_action(s) \n","    ns, r, done, info = env.step(a.item())\n","\n","    states.append(s)\n","    actions.append(a)\n","    rewards.append(r)\n","\n","    s = ns\n","    cum_r += r\n","    if done:\n","      break\n","  \n","  ema.update(cum_r)\n","  if ep % print_every == 0:\n","    print(\"Episode {} || EMA: {}\".format(ep, ema.s))\n","  \n","  states = torch.cat(states, dim=0) #concatenate\n","  actions = torch.cat(actions, dim=0) #concatenate\n","  rewards = torch.tensor(rewards)\n","\n","  episode = (states, actions, rewards)\n","  agent.update_episode(episode)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R_MxhFLcVOXS","executionInfo":{"status":"ok","timestamp":1642778485301,"user_tz":-540,"elapsed":753616,"user":{"displayName":"양현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03791106996878442638"}},"outputId":"5347d811-5743-45c2-90a4-9fb31c205f56"},"execution_count":95,"outputs":[{"output_type":"stream","name":"stdout","text":["Episode 0 || EMA: 20.0\n","Episode 500 || EMA: 326.1607551550861\n","Episode 1000 || EMA: 500.0\n","Episode 1500 || EMA: 141.9705440559444\n"]}]}]}